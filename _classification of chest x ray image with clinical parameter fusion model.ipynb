{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12552aa3-e6c7-4884-bc56-885700fb60b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.9055 | Train Acc: 0.5846 | Val Loss: 0.9611 | Val Acc: 0.5622\n",
      "Epoch 2/10 | Train Loss: 0.7174 | Train Acc: 0.7065 | Val Loss: 1.0542 | Val Acc: 0.5514\n",
      "Epoch 3/10 | Train Loss: 0.6238 | Train Acc: 0.7515 | Val Loss: 1.6763 | Val Acc: 0.3730\n",
      "Epoch 4/10 | Train Loss: 0.5212 | Train Acc: 0.8012 | Val Loss: 1.4521 | Val Acc: 0.5622\n",
      "Epoch 5/10 | Train Loss: 0.4257 | Train Acc: 0.8225 | Val Loss: 1.5937 | Val Acc: 0.4757\n",
      "Epoch 6/10 | Train Loss: 0.3574 | Train Acc: 0.8627 | Val Loss: 1.6661 | Val Acc: 0.4378\n",
      "Epoch 7/10 | Train Loss: 0.3283 | Train Acc: 0.8722 | Val Loss: 1.3682 | Val Acc: 0.5622\n",
      "Epoch 8/10 | Train Loss: 0.2637 | Train Acc: 0.9053 | Val Loss: 1.8565 | Val Acc: 0.4703\n",
      "Epoch 9/10 | Train Loss: 0.2254 | Train Acc: 0.9136 | Val Loss: 2.3903 | Val Acc: 0.3459\n",
      "Epoch 10/10 | Train Loss: 0.1789 | Train Acc: 0.9325 | Val Loss: 2.1019 | Val Acc: 0.5514\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "# -------------------------------\n",
    "# 1️⃣ Dataset Class\n",
    "# -------------------------------\n",
    "class CXRDataset(Dataset):\n",
    "    def __init__(self, csv_path, image_dir, transform=None, clinical_cols=None, label_col=\"label\"):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.clinical_cols = clinical_cols\n",
    "        self.label_col = label_col\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Ensure clinical columns are numeric\n",
    "        for col in clinical_cols:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")  # convert non-numeric → NaN\n",
    "        df = df.dropna(subset=clinical_cols + [label_col])     # drop rows missing clinical data or label\n",
    "\n",
    "        # Only keep images that exist in image_dir\n",
    "        df[\"image_path\"] = df[\"image_id\"].apply(lambda x: os.path.join(image_dir, x))\n",
    "        df = df[df[\"image_path\"].apply(os.path.exists)].reset_index(drop=True)\n",
    "\n",
    "        # Store cleaned dataframe\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # ---- Load Image ----\n",
    "        img = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # ---- Clinical features ----\n",
    "        # Convert to numeric first, then fill NaN and cast\n",
    "        clinical_vals = pd.to_numeric(row[self.clinical_cols], errors=\"coerce\") \\\n",
    "                           .fillna(0).to_numpy(dtype=\"float32\")\n",
    "        clinical = torch.tensor(clinical_vals, dtype=torch.float)\n",
    "\n",
    "        # ---- Label ----\n",
    "        label = torch.tensor(row[self.label_col], dtype=torch.long)\n",
    "\n",
    "        return img, clinical, label\n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ Model: CNN + Clinical MLP + Fusion\n",
    "# -------------------------------\n",
    "class CXRClinicalFusionModel(nn.Module):\n",
    "    def __init__(self, num_tabular_features, num_classes):\n",
    "        super().__init__()\n",
    "        # CNN backbone\n",
    "        base = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.cnn_encoder = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.cnn_dim = base.fc.in_features\n",
    "\n",
    "        # MLP for clinical features\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_tabular_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Fusion classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.cnn_dim + 32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, clinical):\n",
    "        img_feat = self.cnn_encoder(image).view(image.size(0), -1)\n",
    "        tab_feat = self.mlp(clinical)\n",
    "        fused = torch.cat([img_feat, tab_feat], dim=1)\n",
    "        logits = self.classifier(fused)\n",
    "        return logits\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Image Transforms\n",
    "# -------------------------------\n",
    "train_tf = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "val_tf = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Dataset and Dataloader\n",
    "# -------------------------------\n",
    "clinical_cols = [\"age\", \"gender\"]  # example columns\n",
    "label_col = \"label\"\n",
    "img_dir = r\"C:\\Users\\sureb\\dataset\\images\\train\"\n",
    "img_dir1= r\"C:\\Users\\sureb\\dataset\\images\\val\"\n",
    "\n",
    "train_data = CXRDataset(\n",
    "    csv_path=  r\"C:\\Users\\sureb\\dataset\\train.csv\",\n",
    "    image_dir=img_dir,\n",
    "    transform=train_tf,\n",
    "    clinical_cols=clinical_cols,\n",
    "    label_col=label_col\n",
    ")\n",
    "val_data = CXRDataset(\n",
    "    csv_path= r\"C:\\Users\\sureb\\dataset\\val.csv\",\n",
    "    image_dir=img_dir1,\n",
    "    transform=val_tf,\n",
    "    clinical_cols=clinical_cols,\n",
    "    label_col=label_col\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=16, shuffle=False)\n",
    "\n",
    "# -------------------------------\n",
    "# 5️⃣ Training Setup\n",
    "# -------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CXRClinicalFusionModel(\n",
    "    num_tabular_features=len(clinical_cols),\n",
    "    num_classes=3\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# -------------------------------\n",
    "# 6️⃣ Training / Validation Loops\n",
    "# -------------------------------\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for images, clinical, labels in loader:\n",
    "        images, clinical, labels = images.to(device), clinical.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, clinical)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, clinical, labels in loader:\n",
    "            images, clinical, labels = images.to(device), clinical.to(device), labels.to(device)\n",
    "            outputs = model(images, clinical)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "# -------------------------------\n",
    "# 7️⃣ Training Loop\n",
    "# -------------------------------\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f0c53-bd2e-42cc-89a8-e4d9410150ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
